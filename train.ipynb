{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d212867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat May  8 11:15:10 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.119.03   Driver Version: 450.119.03   CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  On   | 00000000:3D:00.0 Off |                  N/A |\n",
      "| 27%   26C    P8    20W / 250W |      3MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  On   | 00000000:3E:00.0 Off |                  N/A |\n",
      "| 27%   25C    P8    13W / 250W |      3MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 208...  On   | 00000000:3F:00.0 Off |                  N/A |\n",
      "| 27%   26C    P8    14W / 250W |      3MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce RTX 208...  On   | 00000000:40:00.0 Off |                  N/A |\n",
      "| 27%   26C    P8     3W / 250W |      3MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce RTX 208...  On   | 00000000:41:00.0 Off |                  N/A |\n",
      "| 27%   25C    P8     9W / 250W |      3MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce RTX 208...  On   | 00000000:60:00.0 Off |                  N/A |\n",
      "| 27%   25C    P8     1W / 250W |      3MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce RTX 208...  On   | 00000000:61:00.0 Off |                  N/A |\n",
      "| 27%   25C    P8    16W / 250W |      3MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce RTX 208...  On   | 00000000:62:00.0 Off |                  N/A |\n",
      "| 27%   25C    P8    13W / 250W |      3MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   8  GeForce RTX 208...  On   | 00000000:63:00.0 Off |                  N/A |\n",
      "| 27%   26C    P8    19W / 250W |      3MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   9  GeForce RTX 208...  On   | 00000000:64:00.0 Off |                  N/A |\n",
      "| 27%   26C    P8    20W / 250W |      3MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d216b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, os\n",
    "import torch\n",
    "import random\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.vdsr import Net\n",
    "from utils.dataset import DatasetFromHdf5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f54142",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48f8815",
   "metadata": {},
   "source": [
    "training settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bab2b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 128 # Training batch size\n",
    "nEpochs = 50 # Number of epochs to train for\n",
    "lr = 0.1 # Learning Rate\n",
    "step = 10 # Sets the learning rate to the initial LR decayed by momentum every n epochs\n",
    "resume = \"\" # Path to checkpoint\n",
    "start_epoch = 1 # Manual epoch number (useful on restarts)\n",
    "clip = 0.4 # Clipping Gradients\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-4\n",
    "pretrained = '' # path to pretrained model\n",
    "checkpoint_step = 10 # the step to store checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f14a611",
   "metadata": {},
   "source": [
    "GPU settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9174be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True # use cuda\n",
    "gpus = \"8\" # gpu ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89eeea60",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "333b0404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> use gpu id: '8'\n"
     ]
    }
   ],
   "source": [
    "if cuda:\n",
    "    print(\"=> use gpu id: '{}'\".format(gpus))\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpus\n",
    "    if not torch.cuda.is_available():\n",
    "        raise Exception(\"No GPU found or Wrong gpu id, please run without --cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d7a73db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  6260\n"
     ]
    }
   ],
   "source": [
    "seed = random.randint(1, 10000)\n",
    "print(\"Random Seed: \", seed)\n",
    "torch.manual_seed(seed)\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d61b26cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Loading datasets\n"
     ]
    }
   ],
   "source": [
    "print(\"===> Loading datasets\")\n",
    "train_set = DatasetFromHdf5(\"data/train.h5\")\n",
    "training_data_loader = DataLoader(dataset=train_set, num_workers=1, batch_size=batchSize, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "261bba89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Building model\n"
     ]
    }
   ],
   "source": [
    "print(\"===> Building model\")\n",
    "model = Net()\n",
    "criterion = nn.MSELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18f82fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Setting GPU\n"
     ]
    }
   ],
   "source": [
    "print(\"===> Setting GPU\")\n",
    "if cuda:\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ae0c7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optionally resume from a checkpoint\n",
    "if resume:\n",
    "    if os.path.isfile(resume):\n",
    "        print(\"=> loading checkpoint '{}'\".format(resume))\n",
    "        checkpoint = torch.load(resume)\n",
    "        start_epoch = checkpoint[\"epoch\"] + 1\n",
    "        model.load_state_dict(checkpoint[\"model\"].state_dict())\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(resume))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "816f1da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optionally copy weights from a checkpoint\n",
    "if pretrained:\n",
    "    if os.path.isfile(pretrained):\n",
    "        print(\"=> loading model '{}'\".format(pretrained))\n",
    "        weights = torch.load(pretrained)\n",
    "        model.load_state_dict(weights['model'].state_dict())\n",
    "    else:\n",
    "        print(\"=> no model found at '{}'\".format(pretrained))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73af8e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 10 epochs\"\"\"\n",
    "    update_lr = lr * (0.5 ** (epoch // step))\n",
    "    return update_lr\n",
    "\n",
    "def train(training_data_loader, optimizer, model, criterion, epoch):\n",
    "    lr = adjust_learning_rate(optimizer, epoch-1)\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = lr\n",
    "\n",
    "    print(\"Epoch = {}, lr = {}\".format(epoch, optimizer.param_groups[0][\"lr\"]))\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    cnt = 0\n",
    "    for iteration, batch in enumerate(training_data_loader, 1):\n",
    "        input, target = Variable(batch[0]), Variable(batch[1], requires_grad=False)\n",
    "\n",
    "        if cuda:\n",
    "            input = input.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "        loss = criterion(model(input), target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() \n",
    "        nn.utils.clip_grad_norm(model.parameters(), clip) \n",
    "        optimizer.step()\n",
    "        total_loss = total_loss + loss.data\n",
    "        cnt = cnt + 1\n",
    "\n",
    "    print(\"===> Epoch[{}]({}/{}): Loss: {:.10f}\".format(epoch, iteration, len(training_data_loader), total_loss/cnt))\n",
    "\n",
    "def save_checkpoint(model, epoch):\n",
    "    model_out_path = \"checkpoint/\" + \"model_epoch_{}.pth\".format(epoch)\n",
    "    state = {\"epoch\": epoch ,\"model\": model}\n",
    "    if not os.path.exists(\"checkpoint/\"):\n",
    "        os.makedirs(\"checkpoint/\")\n",
    "\n",
    "    torch.save(state, model_out_path)\n",
    "\n",
    "    print(\"Checkpoint saved to {}\".format(model_out_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b90ba98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Setting Optimizer\n",
      "===> Training\n",
      "Epoch = 1, lr = 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ichung/MTKlab_SR/sr/lib/python3.6/site-packages/ipykernel_launcher.py:28: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Epoch[1](1134/1134): Loss: 115.1066360474\n",
      "Epoch = 2, lr = 0.1\n",
      "===> Epoch[2](1134/1134): Loss: 68.5899963379\n",
      "Epoch = 3, lr = 0.1\n",
      "===> Epoch[3](1134/1134): Loss: 61.5759239197\n",
      "Epoch = 4, lr = 0.1\n",
      "===> Epoch[4](1134/1134): Loss: 57.9558868408\n",
      "Epoch = 5, lr = 0.1\n",
      "===> Epoch[5](1134/1134): Loss: 55.1494216919\n",
      "Epoch = 6, lr = 0.1\n",
      "===> Epoch[6](1134/1134): Loss: 53.4992904663\n",
      "Epoch = 7, lr = 0.1\n",
      "===> Epoch[7](1134/1134): Loss: 52.2871894836\n",
      "Epoch = 8, lr = 0.1\n",
      "===> Epoch[8](1134/1134): Loss: 51.1326217651\n",
      "Epoch = 9, lr = 0.1\n",
      "===> Epoch[9](1134/1134): Loss: 49.8642082214\n",
      "Epoch = 10, lr = 0.1\n",
      "===> Epoch[10](1134/1134): Loss: 48.8568458557\n",
      "Checkpoint saved to checkpoint/model_epoch_10.pth\n",
      "Epoch = 11, lr = 0.05\n",
      "===> Epoch[11](1134/1134): Loss: 43.9031295776\n",
      "Epoch = 12, lr = 0.05\n",
      "===> Epoch[12](1134/1134): Loss: 42.6961097717\n",
      "Epoch = 13, lr = 0.05\n",
      "===> Epoch[13](1134/1134): Loss: 42.0108985901\n",
      "Epoch = 14, lr = 0.05\n",
      "===> Epoch[14](1134/1134): Loss: 41.2996292114\n",
      "Epoch = 15, lr = 0.05\n",
      "===> Epoch[15](1134/1134): Loss: 40.7633972168\n",
      "Epoch = 16, lr = 0.05\n",
      "===> Epoch[16](1134/1134): Loss: 40.1414260864\n",
      "Epoch = 17, lr = 0.05\n",
      "===> Epoch[17](1134/1134): Loss: 39.8885078430\n",
      "Epoch = 18, lr = 0.05\n",
      "===> Epoch[18](1134/1134): Loss: 39.4217605591\n",
      "Epoch = 19, lr = 0.05\n",
      "===> Epoch[19](1134/1134): Loss: 39.1541900635\n",
      "Epoch = 20, lr = 0.05\n",
      "===> Epoch[20](1134/1134): Loss: 38.7690315247\n",
      "Checkpoint saved to checkpoint/model_epoch_20.pth\n",
      "Epoch = 21, lr = 0.025\n",
      "===> Epoch[21](1134/1134): Loss: 35.6876564026\n",
      "Epoch = 22, lr = 0.025\n",
      "===> Epoch[22](1134/1134): Loss: 35.0714149475\n",
      "Epoch = 23, lr = 0.025\n",
      "===> Epoch[23](1134/1134): Loss: 34.7136344910\n",
      "Epoch = 24, lr = 0.025\n",
      "===> Epoch[24](1134/1134): Loss: 34.3891105652\n",
      "Epoch = 25, lr = 0.025\n",
      "===> Epoch[25](1134/1134): Loss: 34.0883445740\n",
      "Epoch = 26, lr = 0.025\n",
      "===> Epoch[26](1134/1134): Loss: 33.8521614075\n",
      "Epoch = 27, lr = 0.025\n",
      "===> Epoch[27](1134/1134): Loss: 33.6427154541\n",
      "Epoch = 28, lr = 0.025\n",
      "===> Epoch[28](1134/1134): Loss: 33.4232940674\n",
      "Epoch = 29, lr = 0.025\n",
      "===> Epoch[29](1134/1134): Loss: 33.2468376160\n",
      "Epoch = 30, lr = 0.025\n",
      "===> Epoch[30](1134/1134): Loss: 33.1037445068\n",
      "Checkpoint saved to checkpoint/model_epoch_30.pth\n",
      "Epoch = 31, lr = 0.0125\n",
      "===> Epoch[31](1134/1134): Loss: 31.4585151672\n",
      "Epoch = 32, lr = 0.0125\n",
      "===> Epoch[32](1134/1134): Loss: 31.1732101440\n",
      "Epoch = 33, lr = 0.0125\n",
      "===> Epoch[33](1134/1134): Loss: 30.9503822327\n",
      "Epoch = 34, lr = 0.0125\n",
      "===> Epoch[34](1134/1134): Loss: 30.8021888733\n",
      "Epoch = 35, lr = 0.0125\n",
      "===> Epoch[35](1134/1134): Loss: 30.6513824463\n",
      "Epoch = 36, lr = 0.0125\n",
      "===> Epoch[36](1134/1134): Loss: 30.5231189728\n",
      "Epoch = 37, lr = 0.0125\n",
      "===> Epoch[38](1134/1134): Loss: 30.2919311523\n",
      "Epoch = 39, lr = 0.0125\n",
      "===> Epoch[39](1134/1134): Loss: 30.1733970642\n",
      "Epoch = 40, lr = 0.0125\n",
      "===> Epoch[40](1134/1134): Loss: 30.0565261841\n",
      "Checkpoint saved to checkpoint/model_epoch_40.pth\n",
      "Epoch = 41, lr = 0.00625\n",
      "===> Epoch[41](1134/1134): Loss: 29.2752075195\n",
      "Epoch = 42, lr = 0.00625\n",
      "===> Epoch[42](1134/1134): Loss: 29.1278343201\n",
      "Epoch = 43, lr = 0.00625\n",
      "===> Epoch[43](1134/1134): Loss: 29.0283145905\n",
      "Epoch = 44, lr = 0.00625\n",
      "===> Epoch[44](1134/1134): Loss: 28.9324874878\n",
      "Epoch = 45, lr = 0.00625\n",
      "===> Epoch[45](1134/1134): Loss: 28.8514995575\n",
      "Epoch = 46, lr = 0.00625\n",
      "===> Epoch[46](1134/1134): Loss: 28.7842826843\n",
      "Epoch = 47, lr = 0.00625\n",
      "===> Epoch[47](1134/1134): Loss: 28.7033920288\n",
      "Epoch = 48, lr = 0.00625\n",
      "===> Epoch[48](1134/1134): Loss: 28.6406497955\n",
      "Epoch = 49, lr = 0.00625\n",
      "===> Epoch[49](1134/1134): Loss: 28.5696830750\n",
      "Epoch = 50, lr = 0.00625\n",
      "===> Epoch[50](1134/1134): Loss: 28.5191936493\n",
      "Checkpoint saved to checkpoint/model_epoch_50.pth\n"
     ]
    }
   ],
   "source": [
    "print(\"===> Setting Optimizer\")\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "print(\"===> Training\")\n",
    "for epoch in range(start_epoch, nEpochs + 1):\n",
    "    train(training_data_loader, optimizer, model, criterion, epoch)\n",
    "    if epoch % checkpoint_step == 0:\n",
    "        save_checkpoint(model, epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
